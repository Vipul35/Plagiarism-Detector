{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vipul\n",
      "[nltk_data]     Kapoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vipul\n",
      "[nltk_data]     Kapoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vipul Kapoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Vipul\n",
      "[nltk_data]     Kapoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Vipul\n",
      "[nltk_data]     Kapoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "#all imported packages\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the functions and declarations\n",
    "\n",
    "#object creation for stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "#to check for nouns\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "\n",
    "###################################################pre-processing steps#################################################\n",
    "\n",
    "\n",
    "#sentence_tokenization\n",
    "def sen_tokenize(text1):\n",
    "    text = text1.read()\n",
    "    sen_list = nltk.tokenize.sent_tokenize(text)\n",
    "    return sen_list\n",
    "\n",
    "#word_tokenization\n",
    "def wor_tokenize(sen_list):  \n",
    "    word_list = []\n",
    "    for terms in sen_list:\n",
    "        text_tokens = nltk.tokenize.word_tokenize(terms)\n",
    "        word_list.append(text_tokens)\n",
    "    return word_list\n",
    "\n",
    "\n",
    "#to remove the stop words      \n",
    "def stopword_removal(a_list):\n",
    "    word_list = []\n",
    "    for terms in a_list:\n",
    "        tokens_without_sw = [word for word in terms if not word in stopwords.words()]\n",
    "        word_list.append(tokens_without_sw)\n",
    "    return word_list\n",
    "\n",
    "\n",
    "#to remove the punctuation\n",
    "def remove_punctuation(a_list):\n",
    "    word_list = []\n",
    "    for terms in a_list:\n",
    "        tokens_without_sw = [word for word in terms if word.isalnum()]\n",
    "        word_list.append(tokens_without_sw)\n",
    "    return word_list\n",
    "\n",
    "\n",
    "#concept extraction: to extract the important features like nouns in our case\n",
    "def concept_extraction(a_list):\n",
    "    b_list=[]\n",
    "    \n",
    "    for terms in a_list:\n",
    "        #extracting nouns\n",
    "        nouns = [word for (word, pos) in nltk.pos_tag(terms) if is_noun(pos)] \n",
    "        tokens_without_sw1=[]\n",
    "        for word in nouns:\n",
    "            #stemming\n",
    "            tokens_without_sw1.append(porter.stem(word))\n",
    "            #adding synonyms to the list so that it can catch alternative words used\n",
    "            synset=wordnet.synsets(word)\n",
    "            tokens_without_sw1.append(synset[0].lemmas()[0].name())\n",
    "        b_list.append(tokens_without_sw1)\n",
    "    return b_list\n",
    "\n",
    "#creating topic signature node\n",
    "def get_topic_signature(b_list):\n",
    "    topic_signature = list(set().union(*b_list))\n",
    "    return topic_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document\n",
      "After Sentence Tokenization\n",
      "['The legal system is made up of civil courts, criminal courts and specialty courts such as family law courts and bankruptcy court.', 'Each court has its own jurisdiction, which refers to the cases that the court is allowed to hear.', 'In some instances, a case can only be heard in one type of court.', 'For example, a bankruptcy case must be heard in a bankruptcy court.', 'In other instances, there may be several potential courts with jurisdiction.', 'For example, a federal criminal court and a state criminal court would each have jurisdiction over a crime that is a federal drug offense but that is also an offense on the state level.']\n",
      "\n",
      "After Word Tokenization\n",
      "[['The', 'legal', 'system', 'is', 'made', 'up', 'of', 'civil', 'courts', ',', 'criminal', 'courts', 'and', 'specialty', 'courts', 'such', 'as', 'family', 'law', 'courts', 'and', 'bankruptcy', 'court', '.'], ['Each', 'court', 'has', 'its', 'own', 'jurisdiction', ',', 'which', 'refers', 'to', 'the', 'cases', 'that', 'the', 'court', 'is', 'allowed', 'to', 'hear', '.'], ['In', 'some', 'instances', ',', 'a', 'case', 'can', 'only', 'be', 'heard', 'in', 'one', 'type', 'of', 'court', '.'], ['For', 'example', ',', 'a', 'bankruptcy', 'case', 'must', 'be', 'heard', 'in', 'a', 'bankruptcy', 'court', '.'], ['In', 'other', 'instances', ',', 'there', 'may', 'be', 'several', 'potential', 'courts', 'with', 'jurisdiction', '.'], ['For', 'example', ',', 'a', 'federal', 'criminal', 'court', 'and', 'a', 'state', 'criminal', 'court', 'would', 'each', 'have', 'jurisdiction', 'over', 'a', 'crime', 'that', 'is', 'a', 'federal', 'drug', 'offense', 'but', 'that', 'is', 'also', 'an', 'offense', 'on', 'the', 'state', 'level', '.']]\n",
      "\n",
      "After removing stop words\n",
      "[['The', 'legal', 'system', 'made', 'civil', 'courts', ',', 'criminal', 'courts', 'specialty', 'courts', 'family', 'law', 'courts', 'bankruptcy', 'court', '.'], ['Each', 'court', 'jurisdiction', ',', 'refers', 'cases', 'court', 'allowed', 'hear', '.'], ['In', 'instances', ',', 'case', 'heard', 'type', 'court', '.'], ['For', 'example', ',', 'bankruptcy', 'case', 'must', 'heard', 'bankruptcy', 'court', '.'], ['In', 'instances', ',', 'may', 'several', 'potential', 'courts', 'jurisdiction', '.'], ['For', 'example', ',', 'federal', 'criminal', 'court', 'state', 'criminal', 'court', 'would', 'jurisdiction', 'crime', 'federal', 'offense', 'offense', 'state', 'level', '.']]\n",
      "\n",
      "After removing punctuations\n",
      "[['The', 'legal', 'system', 'made', 'civil', 'courts', 'criminal', 'courts', 'specialty', 'courts', 'family', 'law', 'courts', 'bankruptcy', 'court'], ['Each', 'court', 'jurisdiction', 'refers', 'cases', 'court', 'allowed', 'hear'], ['In', 'instances', 'case', 'heard', 'type', 'court'], ['For', 'example', 'bankruptcy', 'case', 'must', 'heard', 'bankruptcy', 'court'], ['In', 'instances', 'may', 'several', 'potential', 'courts', 'jurisdiction'], ['For', 'example', 'federal', 'criminal', 'court', 'state', 'criminal', 'court', 'would', 'jurisdiction', 'crime', 'federal', 'offense', 'offense', 'state', 'level']]\n",
      "\n",
      "The concepts list extracted from original document\n",
      "[['system', 'system', 'court', 'court', 'court', 'court', 'specialti', 'forte', 'court', 'court', 'famili', 'family', 'law', 'law', 'court', 'court', 'bankruptci', 'bankruptcy', 'court', 'court'], ['court', 'court', 'jurisdict', 'legal_power', 'refer', 'mention', 'case', 'case', 'court', 'court'], ['instanc', 'case', 'case', 'case', 'type', 'type', 'court', 'court'], ['exampl', 'example', 'bankruptci', 'bankruptcy', 'case', 'case', 'bankruptci', 'bankruptcy', 'court', 'court'], ['instanc', 'case', 'court', 'court', 'jurisdict', 'legal_power'], ['exampl', 'example', 'court', 'court', 'state', 'state', 'court', 'court', 'crime', 'crime', 'offens', 'discourtesy', 'offens', 'discourtesy', 'state', 'state', 'level', 'degree']]\n",
      "\n",
      "Topic signature of original document\n",
      "['crime', 'level', 'bankruptcy', 'specialti', 'court', 'forte', 'instanc', 'type', 'system', 'exampl', 'law', 'discourtesy', 'jurisdict', 'bankruptci', 'legal_power', 'family', 'degree', 'example', 'case', 'state', 'offens', 'famili', 'refer', 'mention']\n"
     ]
    }
   ],
   "source": [
    "######################processing original document#############################\n",
    "\n",
    "text1 = open(\"original.txt\",\"r\")\n",
    "\n",
    "print(\"Original Document\")\n",
    "\n",
    "b_list=sen_tokenize(text1)\n",
    "print(\"After Sentence Tokenization\")\n",
    "print(b_list)\n",
    "print()\n",
    "\n",
    "b_list=wor_tokenize(b_list)\n",
    "print(\"After Word Tokenization\")\n",
    "print(b_list)\n",
    "print()\n",
    "\n",
    "b_list=stopword_removal(b_list)\n",
    "print(\"After removing stop words\")\n",
    "print(b_list)\n",
    "print()\n",
    "\n",
    "b_list=remove_punctuation(b_list)\n",
    "print(\"After removing punctuations\")\n",
    "print(b_list)\n",
    "print()\n",
    "\n",
    "b_list=concept_extraction(b_list)\n",
    "print(\"The concepts list extracted from original document\")\n",
    "print(b_list)\n",
    "print()\n",
    "\n",
    "ts_1=get_topic_signature(b_list)\n",
    "print(\"Topic signature of original document\")\n",
    "print(ts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspected Document\n",
      "After Sentence Tokenization\n",
      "['The legal system is comprised of criminal and civil courts and specialty courts like bankruptcy and family law courts.', 'Every one of the courts is vested with its own jurisdiction.', 'Jurisdiction means the types of cases each court is permitted to rule on.', 'Sometimes, only one type of court can hear a particular case.', 'For instance, bankruptcy cases an be ruled on only in bankruptcy court.', 'In other situations, it is possible for more than one court to have jurisdiction.', 'For instance, both a state and federal criminal court could have authority over a criminal case that is illegal under federal and state drug laws.']\n",
      "\n",
      "After Word Tokenization\n",
      "[['The', 'legal', 'system', 'is', 'comprised', 'of', 'criminal', 'and', 'civil', 'courts', 'and', 'specialty', 'courts', 'like', 'bankruptcy', 'and', 'family', 'law', 'courts', '.'], ['Every', 'one', 'of', 'the', 'courts', 'is', 'vested', 'with', 'its', 'own', 'jurisdiction', '.'], ['Jurisdiction', 'means', 'the', 'types', 'of', 'cases', 'each', 'court', 'is', 'permitted', 'to', 'rule', 'on', '.'], ['Sometimes', ',', 'only', 'one', 'type', 'of', 'court', 'can', 'hear', 'a', 'particular', 'case', '.'], ['For', 'instance', ',', 'bankruptcy', 'cases', 'an', 'be', 'ruled', 'on', 'only', 'in', 'bankruptcy', 'court', '.'], ['In', 'other', 'situations', ',', 'it', 'is', 'possible', 'for', 'more', 'than', 'one', 'court', 'to', 'have', 'jurisdiction', '.'], ['For', 'instance', ',', 'both', 'a', 'state', 'and', 'federal', 'criminal', 'court', 'could', 'have', 'authority', 'over', 'a', 'criminal', 'case', 'that', 'is', 'illegal', 'under', 'federal', 'and', 'state', 'drug', 'laws', '.']]\n",
      "\n",
      "After removing stop words\n",
      "[['The', 'legal', 'system', 'comprised', 'criminal', 'civil', 'courts', 'specialty', 'courts', 'like', 'bankruptcy', 'family', 'law', 'courts', '.'], ['Every', 'courts', 'vested', 'jurisdiction', '.'], ['Jurisdiction', 'means', 'types', 'cases', 'court', 'permitted', 'rule', '.'], ['Sometimes', ',', 'type', 'court', 'hear', 'particular', 'case', '.'], ['For', 'instance', ',', 'bankruptcy', 'cases', 'ruled', 'bankruptcy', 'court', '.'], ['In', 'situations', ',', 'possible', 'court', 'jurisdiction', '.'], ['For', 'instance', ',', 'state', 'federal', 'criminal', 'court', 'could', 'authority', 'criminal', 'case', 'illegal', 'federal', 'state', 'laws', '.']]\n",
      "\n",
      "After removing punctuations\n",
      "[['The', 'legal', 'system', 'comprised', 'criminal', 'civil', 'courts', 'specialty', 'courts', 'like', 'bankruptcy', 'family', 'law', 'courts'], ['Every', 'courts', 'vested', 'jurisdiction'], ['Jurisdiction', 'means', 'types', 'cases', 'court', 'permitted', 'rule'], ['Sometimes', 'type', 'court', 'hear', 'particular', 'case'], ['For', 'instance', 'bankruptcy', 'cases', 'ruled', 'bankruptcy', 'court'], ['In', 'situations', 'possible', 'court', 'jurisdiction'], ['For', 'instance', 'state', 'federal', 'criminal', 'court', 'could', 'authority', 'criminal', 'case', 'illegal', 'federal', 'state', 'laws']]\n",
      "\n",
      "The concepts list extracted from suspected document\n",
      "[['system', 'system', 'court', 'court', 'specialti', 'forte', 'court', 'court', 'bankruptci', 'bankruptcy', 'famili', 'family', 'law', 'law', 'court', 'court'], ['court', 'court', 'jurisdict', 'legal_power'], ['jurisdict', 'legal_power', 'type', 'type', 'case', 'case', 'court', 'court', 'rule', 'rule'], ['court', 'court', 'case', 'case'], ['instanc', 'case', 'bankruptci', 'bankruptcy', 'case', 'case', 'bankruptci', 'bankruptcy', 'court', 'court'], ['situat', 'situation', 'court', 'court', 'jurisdict', 'legal_power'], ['instanc', 'case', 'state', 'state', 'court', 'court', 'case', 'case', 'state', 'state', 'law', 'Torah']]\n",
      "\n",
      "Topic signature of suspected document\n",
      "['bankruptcy', 'specialti', 'court', 'Torah', 'situat', 'forte', 'instanc', 'type', 'system', 'law', 'jurisdict', 'bankruptci', 'legal_power', 'family', 'case', 'situation', 'state', 'famili', 'rule']\n"
     ]
    }
   ],
   "source": [
    "######################processing plagiarised document#############################\n",
    "\n",
    "\n",
    "text2 = open(\"plagiarised text sample.txt\",\"r\")\n",
    "\n",
    "print(\"Suspected Document\")\n",
    "c_list=sen_tokenize(text2)\n",
    "print(\"After Sentence Tokenization\")\n",
    "print(c_list)\n",
    "print()\n",
    "\n",
    "c_list=wor_tokenize(c_list)\n",
    "print(\"After Word Tokenization\")\n",
    "print(c_list)\n",
    "print()\n",
    "\n",
    "c_list=stopword_removal(c_list)\n",
    "print(\"After removing stop words\")\n",
    "print(c_list)\n",
    "print()\n",
    "\n",
    "c_list=remove_punctuation(c_list)\n",
    "print(\"After removing punctuations\")\n",
    "print(c_list)\n",
    "print()\n",
    "\n",
    "c_list=concept_extraction(c_list)\n",
    "print(\"The concepts list extracted from suspected document\")\n",
    "print(c_list)\n",
    "print()\n",
    "\n",
    "ts_2=get_topic_signature(c_list)\n",
    "print(\"Topic signature of suspected document\")\n",
    "print(ts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of plagiarism found 53.57142857142857\n",
      "\n",
      "The copied concepts are\n",
      "['system', 'case', 'law', 'bankruptcy', 'jurisdict', 'state', 'specialti', 'court', 'famili', 'forte', 'instanc', 'bankruptci', 'legal_power', 'type', 'family']\n"
     ]
    }
   ],
   "source": [
    "plag_percentage = len(list(set(ts_1) & set(ts_2)))/len(list(set(ts_1).union(set(ts_2))))*100\n",
    "print(\"percentage of plagiarism found\",plag_percentage)\n",
    "print()\n",
    "print(\"The copied concepts are\")\n",
    "print(list(set(ts_1) & set(ts_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the tolerance level of plagiarism\n",
    "tolerance=30\n",
    "copied_content = list(set(ts_1) & set(ts_2))\n",
    "\n",
    "#function for calculation of copied content within the document\n",
    "def localization(sen_list):    \n",
    "    copied_sen = []\n",
    "    print(\"plagiarism percentage of each sentence from start\")\n",
    "    for lists in sen_list:\n",
    "        plag_percentage1 = len(list(set(copied_content) & set(lists)))/len(list(set(copied_content).union(set(lists))))*100\n",
    "        print(\" \",plag_percentage1)\n",
    "        if plag_percentage1 > tolerance:\n",
    "            copied_sen.append(sen_list.index(lists)+1)\n",
    "    return copied_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plagiarism percentage of each sentence from start\n",
      "  60.0\n",
      "  20.0\n",
      "  31.25\n",
      "  13.333333333333334\n",
      "  33.33333333333333\n",
      "  17.647058823529413\n",
      "  31.25\n",
      "[1, 3, 5, 7] sentences are copied with high accuracy in suspected document\n"
     ]
    }
   ],
   "source": [
    "copied_sen2 = localization(c_list)\n",
    "print(copied_sen2,\"sentences are copied with high accuracy in document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
